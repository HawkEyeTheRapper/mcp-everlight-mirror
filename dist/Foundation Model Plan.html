<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Foundation Model Plan</title>
<style id="everlight-nav-style">
      .everlight-nav {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 12px 16px;
        margin-bottom: 20px;
        border-bottom: 1px solid rgba(127,127,127,.3);
        font-family: system-ui, sans-serif;
      }
      .everlight-nav a {
        text-decoration: none;
        font-weight: 600;
        opacity: .9;
      }
      .everlight-nav a:hover {
        text-decoration: underline;
        opacity: 1;
      }
    </style>
</head>
<body>
<nav class="everlight-nav">
  <a class="prev" href="Format markdown files.html">‚üµ Previous</a>
  <a class="index" href="index.html">üè† Index</a>
  <a class="next" href="Fractal dimensions and symbolism.html">Next ‚ü∂</a>
</nav>
<hr />
<p>conversation_id: "689f33c9-0cf0-8329-ab0b-0ee2177f3e08"
title: "Foundation Model Plan"
accounts: ["Account1_exports"]
models: []
tags: []
message_count: 21</p>
<hr />
<h1 id="foundation-model-plan">Foundation Model Plan</h1>
<h2 id="system">‚Äî system</h2>
<h2 id="2025-08-15t131905530577z-system">2025-08-15T13:19:05.530577Z ‚Äî system</h2>
<h2 id="2025-08-15t131906030280z-tool">2025-08-15T13:19:06.030280Z ‚Äî tool</h2>
<h2 id="2025-08-15t131906721000z-user">2025-08-15T13:19:06.721000Z ‚Äî user</h2>
<p>EverLight OS ‚Äî Foundation Model Plan (Voyagers + EnergeticSynthesis)
0) Green-lights &amp; guardrails</p>
<p>Rights/IP: Get written permission to train on EnergeticSynthesis.com content (copyright).</p>
<p>Privacy: Scrub PII; log removals.</p>
<p>Attribution mode: Keep doc IDs to enable citations.</p>
<p>1) Data fabric (three-key set)</p>
<p>Corpora</p>
<p>V1: Voyagers Material ‚Äî part 1</p>
<p>V2: Voyagers Material ‚Äî part 2</p>
<p>ES: EnergeticSynthesis.com (all articles/posts)</p>
<p>Ingestion ‚Üí Lake</p>
<p>Crawl/collect ‚Üí S3 (s3://everlight/raw/{V1|V2|ES}/...)</p>
<p>Normalize to JSONL:
{"doc_id","source":{"set":"V1|V2|ES"}, "title","author","date","url","section","text"}</p>
<p>Chunking: 800‚Äì1200 tokens with 10‚Äì15% overlap; keep paragraph &amp; section boundaries.</p>
<p>Metadata: topic tags (mythic, esoteric, technique, protocol), time, source, quality score.</p>
<p>De-dupe: MinHash/SimHash + exact-hash prune.</p>
<p>Quality filters: length, language, perplexity, blacklist of boilerplate.</p>
<p>2) Retrieval layer (ships day 1)</p>
<p>Vector DB: FAISS/Weaviate (embeddings via a long-context model).</p>
<p>Symbolic search: OpenSearch/BM25 over titles/headers.</p>
<p>Reranker: Cross-encoder for top-k re-ranking.</p>
<p>Routing: If query contains {mythic/symbolic} ‚Üí V1/V2 boost; {practice/protocol} ‚Üí ES boost.</p>
<p>This gives you immediate RAG capability while training proceeds.</p>
<p>3) Model strategy</p>
<p>Base FM (pick one):</p>
<p>Bedrock-hosted FM (e.g., Anthropic / Amazon Titan) or</p>
<p>Open weights (e.g., Llama-class) hosted on SageMaker</p>
<p>Stage A ‚Äì Domain Adaptation (DAPT)</p>
<p>Continue pretraining on V1+V2+ES mix (80‚Äì90% tokens unsupervised LM).</p>
<p>Sampling: temperature-based; enforce mix ratios (e.g., V1:35%, V2:35%, ES:30%).</p>
<p>Objectives: next-token LM; add span corruption for robustness.</p>
<p>Output: EverLight-FM-D1 (your Foundation Model).</p>
<p>Stage B ‚Äì Task Adapters (LoRA/PEFT)</p>
<p>Mythic Reasoner (symbol/analogy chains) ‚Üí LoRA on V1/V2 exemplars.</p>
<p>Energy Praxis (protocols/how-to) ‚Üí LoRA on ES procedural chunks.</p>
<p>Navigator (decision support) ‚Üí LoRA using curated Q‚ÜíA, decision trees.</p>
<p>Stage C ‚Äì Instruction tuning</p>
<p>SFT on mixed Q/A derived from the corpora + evaluator-written prompts.</p>
<p>Add citation training: require the model to return doc_id:span when answering.</p>
<p>4) Orchestration (MoE-style routing without heavy MoE)</p>
<p>Router (small classifier) reads the user query ‚Üí selects: {RAG-only | FM | FM+RAG | Specific Adapter}.</p>
<p>Answerer: chosen adapter, with top-k retrieved passages injected.</p>
<p>Guardrails: content policy, claim checker (answer must quote or cite).</p>
<p>5) Evaluation (bake this in)</p>
<p>Truthfulness@K with citation match (does the cited span support the claim?).</p>
<p>Mythic coherence score (expert rubric).</p>
<p>Actionability score (for protocols).</p>
<p>Latency &amp; cost (p99, $/1k tokens).</p>
<p>Regression set of ~300 canonical questions across V1/V2/ES.</p>
<p>6) Delivery on AWS</p>
<p>Storage/Lake: S3 + Glue catalog.</p>
<p>Pipelines: Step Functions/Airflow for ETL, training jobs on SageMaker.</p>
<p>Search: OpenSearch + FAISS/Weaviate.</p>
<p>Serving: SageMaker endpoints (FM + adapters).</p>
<p>App: API (FastAPI) + lightweight UI; Bedrock for fallback FMs if needed.</p>
<p>Versioning: DVC or LakeFS for datasets; MLflow for model runs.</p>
<p>7) Phased rollout</p>
<p>Week 0‚Äì2: Build ingestion, de-dupe, chunking, vector search. Ship RAG alpha.</p>
<p>Week 3‚Äì6: DAPT pretrain ‚Üí EverLight-FM-D1.</p>
<p>Week 7‚Äì9: LoRA adapters (Mythic, Praxis, Navigator).</p>
<p>Week 10+: Instruction tuning + citation training; eval harness; pilot users.</p>
<p>8) Risks &amp; mitigations</p>
<p>IP/Copyright: get permissions; throttle public exposure; add robots-respectful crawl.</p>
<p>Overfit/style lock-in: mix generic text (5‚Äì10%) during DAPT to preserve fluency.</p>
<p>Hallucinations: enforce retrieval-grounding; refuse when no supporting span.</p>
<p>Ontology drift: maintain a concept taxonomy; run periodic alignment checks.</p>
<p>TL;DR: Use V1, V2, and EnergeticSynthesis as the foundation corpus, do continued pretraining to mint EverLight-FM, then add lightweight adapters for the three core capabilities, all fronted by a RAG layer with citations. You can ship useful value with RAG immediately while the FM trains.</p>
<h2 id="2025-08-15t131907162810z-tool">2025-08-15T13:19:07.162810Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907319737z-tool">2025-08-15T13:19:07.319737Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907337410z-tool">2025-08-15T13:19:07.337410Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907361468z-tool">2025-08-15T13:19:07.361468Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907490426z-tool">2025-08-15T13:19:07.490426Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907625243z-assistant">2025-08-15T13:19:07.625243Z ‚Äî assistant</h2>
<p>Ethan ‚Äî this <strong>Foundation Model Plan</strong> you outlined can be implemented directly on the Voyagers corpus you‚Äôve restored and expanded, and the steps are already well-supported by the structure of the material you‚Äôve got in the uploads.  </p>
<p>From the restored <strong>Voyagers Volume I &amp; II</strong> and the <strong>EverLight Codex Archive</strong> front matter„Äê27‚Ä†front_matter.md‚Ä†L1-L40„Äë through the detailed multi-dimensional frameworks in chapters like <strong>Human Origins &amp; Hybridization</strong>„Äê21‚Ä†chapter_3.md‚Ä†L1-L40„Äë, <strong>Levels of Identity &amp; Components of Mind</strong>„Äê26‚Ä†chapter_7.md‚Ä†L1-L40„Äë, and <strong>Special Projects</strong>„Äê24‚Ä†chapter_6.md‚Ä†L1-L40„Äë, you‚Äôve got a clean separation of:</p>
<ul>
<li><strong>Mythic/symbolic strata</strong> (Zionites, Turaneusiam, Emerald Covenant) ‚Äî ideal for the <em>Mythic Reasoner</em> adapter.</li>
<li><strong>Practical/technical strata</strong> (Keylontic Morphogenetic Science, meditation techniques, crop circle frequency work) ‚Äî ideal for the <em>Energy Praxis</em> adapter.</li>
<li><strong>Meta-structural strata</strong> (Guardian Alliance, IAFW, universal service orders) ‚Äî ideal for the <em>Navigator</em> adapter.</li>
</ul>
<p>This directly maps to your plan‚Äôs <strong>V1 / V2 / ES triple-key set</strong> with minimal transformation work.  </p>
<p>The extra win here is that the Voyagers content is already in <strong>sectioned, chapter-based format</strong> with clear topic boundaries ‚Äî perfect for your <strong>800‚Äì1200 token chunking with 10‚Äì15% overlap</strong>. That means you can move straight to:</p>
<ol>
<li><strong>S3 Ingestion &amp; JSONL Normalization</strong> (doc_id = <code>{V1|V2}-{chapter}-{section}</code>).</li>
<li><strong>Vector &amp; symbolic indexing</strong> ‚Äî you‚Äôll want dual FAISS + BM25 here so a ‚ÄúGuardian Alliance‚Äù query can pull both the factual CDT-Plate history and the symbolic meaning layer.</li>
<li><strong>DAPT pretraining</strong> on this curated Voyagers set before merging in EnergeticSynthesis articles.</li>
</ol>
<p>If you want, I can sketch you the <strong>exact JSONL schema + chunking pipeline</strong> using the Voyagers MD files you‚Äôve already got so you can feed it into S3 and have the retrieval layer operational in week 1, exactly as your rollout plan specifies.  </p>
<p>Do you want me to do that next? That would make this plan executable tomorrow.</p>
<h2 id="2025-08-15t131907632870z-tool">2025-08-15T13:19:07.632870Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907711053z-tool">2025-08-15T13:19:07.711053Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907717296z-tool">2025-08-15T13:19:07.717296Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907724063z-tool">2025-08-15T13:19:07.724063Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907811124z-tool">2025-08-15T13:19:07.811124Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907934534z-tool">2025-08-15T13:19:07.934534Z ‚Äî tool</h2>
<h2 id="2025-08-15t131907992915z-tool">2025-08-15T13:19:07.992915Z ‚Äî tool</h2>
<h2 id="2025-08-15t131908032078z-tool">2025-08-15T13:19:08.032078Z ‚Äî tool</h2>
<p>Please remember to search the user's documents if an answer to their question is not contained in the above snippets. You cannot mclick into this file- if needed, you can use msearch to search it for additional information.</p>
<h2 id="2025-08-15t131908056989z-assistant">2025-08-15T13:19:08.056989Z ‚Äî assistant</h2>
<h2 id="2025-08-15t132019704603z-assistant">2025-08-15T13:20:19.704603Z ‚Äî assistant</h2>
<p>Got it ‚Äî we can keep the blueprint on standby until you‚Äôre ready to move from <strong>theory mode ‚Üí AWS hands-on</strong>.  </p>
<p>Honestly, you‚Äôre already in a good position because you‚Äôve got:  </p>
<ul>
<li><strong>A well-structured corpus</strong> (Voyagers) with clear topical boundaries.  </li>
<li><strong>A deployment roadmap</strong> (your Foundation Model Plan).  </li>
<li><strong>Alignment with AWS-native tooling</strong> (S3, Glue, SageMaker, OpenSearch).  </li>
</ul>
<p>Once you‚Äôve absorbed the AWS course content, it‚Äôll feel less like magic and more like you‚Äôre just <strong>wiring up components you already understand</strong>, which is a lot more fun than scrambling to learn the tools mid-build.  </p>
<p>We can also use the meantime to quietly <strong>refine metadata, tagging, and concept taxonomy</strong> so the ingestion pipeline will be ‚Äúdrop-in ready‚Äù when you flip the switch.  </p>
<p>Sounds like we‚Äôll hit that ‚Äúahead of the curve‚Äù feeling in <em>both</em> theory and practice.  </p>
<h2 id="2025-08-15t132020647000z-user">2025-08-15T13:20:20.647000Z ‚Äî user</h2>
<p>Let's wait until I catch up on the actual AWS course material so I can feel as if I understand more of the process before implementing it. But it's good to know we're already well ahead of the curve haha</p>
</body>
</html>